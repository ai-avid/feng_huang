import pandas as pd
import numpy as np

# --- Parameters ---
CONVERSION_RATE = 0.15 # Percentage of unique users who will be randomly marked as converted
# If you want to use a lookback window for MT models (optional):
# LOOKBACK_DAYS = 30
# USE_LOOKBACK_WINDOW = False # Set to True to enable lookback window for MT

# --- 1. Sample Data Creation ---
# Create a DataFrame similar to your input data
# (Replace this with loading your actual data using pd.read_csv, pd.read_excel, etc.)
data = {
    'user': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C', 'D', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'H'],
    'visit_date': pd.to_datetime([
        '2025-03-01', '2025-03-05', '2025-03-10', # A
        '2025-03-02', '2025-03-12',             # B
        '2025-03-03', '2025-03-06', '2025-03-09', '2025-03-11', # C
        '2025-03-04',                           # D
        '2025-03-07', '2025-03-13',             # E
        '2025-03-08', '2025-03-14', '2025-03-15', # F
        '2025-03-16', '2025-03-17',             # G
        '2025-03-18'                            # H
    ]),
    'channel': [
        'Search', 'Display', 'Search', # A
        'Display', 'Search',         # B
        'TV', 'Search', 'Display', 'Search', # C
        'TV',                           # D
        'Display', 'TV',             # E
        'Search', 'TV', 'Display',   # F
        'Display','Search',          # G
        'Search'                     # H
    ]
}
df = pd.DataFrame(data)
print("--- Original Visit Data ---")
print(df)
print("\n")

# --- 2. Simulate Conversion Status ---
unique_users = df['user'].unique()
num_converters = int(len(unique_users) * CONVERSION_RATE)
# Randomly choose which users converted
np.random.seed(42) # for reproducible results
converting_users = np.random.choice(unique_users, size=num_converters, replace=False)
print(f"--- Simulation ---")
print(f"Total unique users: {len(unique_users)}")
print(f"Simulated conversion rate: {CONVERSION_RATE:.0%}")
print(f"Number of converting users: {len(converting_users)}")
print(f"Converting users: {list(converting_users)}\n")

# --- 3. Find Last Touch for Every User ---
# Sort data first to ensure 'last()' picks the latest date's record
df_sorted = df.sort_values(by=['user', 'visit_date'])
# Group by user and get the last record (which includes the last date and channel)
last_touches_all = df_sorted.groupby('user').last().reset_index()
# Rename columns for clarity, especially if original df had columns named 'visit_date' or 'channel'
last_touches_all = last_touches_all.rename(columns={
    'visit_date': 'last_visit_date',
    'channel': 'last_touch_channel'
})

# --- 4. Isolate Last Touch Data for Converted Users ---
# Filter the last touch data to include only those users marked as converters
last_touch_converters = last_touches_all[last_touches_all['user'].isin(converting_users)].copy()
print("--- Last Touch Data for Converters ---")
# Display the user, their last visit date (implicit conversion date), and the last channel
print(last_touch_converters[['user', 'last_visit_date', 'last_touch_channel']])
print("\n")

# --- 5. Calculate Last-Touch Attribution ---
# Calculate the percentage distribution of last touch channels among converters
lt_attribution = last_touch_converters['last_touch_channel'].value_counts(normalize=True) * 100
# Convert the resulting Series to a DataFrame for easier merging later
lt_attribution = lt_attribution.reset_index()
# Rename columns for clarity in the final table
lt_attribution.columns = ['Channel', 'Last_Touch_%']
print("--- Last-Touch Attribution (% of Converters) ---")
print(lt_attribution)
print("\n")

# --- 6. Define Journeys for Converted Users ---
# Filter the original dataframe to get all visits for the converting users
journeys_converters = df[df['user'].isin(converting_users)].sort_values(by=['user', 'visit_date']).copy()
# This dataframe now holds the full journey sequence for each converting user

# --- 7. Calculate Multi-Touch Attribution ---

# --- 7a. Linear Model ---
def apply_linear(group):
    """Assigns equal credit (1/N) to each touchpoint in the group (user's journey)."""
    n = len(group)
    if n == 0:
        return pd.Series(dtype=float) # Return empty series if group is empty
    # Count occurrences of each channel in the journey
    channel_counts = group['channel'].value_counts()
    # Calculate credit: count for channel * (1 / total visits)
    credits = channel_counts * (1.0 / n)
    return credits

# Apply the function to each user's journey within the converters dataframe
# The result is typically a Series with a MultiIndex (user, channel)
linear_credits_per_user = journeys_converters.groupby('user', group_keys=True).apply(apply_linear) # group_keys=True often helps ensure structure

# Sum credits across all converting users for each channel
# Check if the result has a MultiIndex (user, channel) or just channel index
if isinstance(linear_credits_per_user.index, pd.MultiIndex):
     # If MultiIndex (user, channel), group by the 'channel' level (usually level 1)
     mt_linear_total_credits = linear_credits_per_user.groupby(level='channel').sum()
else:
    # If the index is just 'channel' (less common for complex apply), group by the index itself
    mt_linear_total_credits = linear_credits_per_user.groupby(linear_credits_per_user.index).sum()

# Normalize by the number of converters to get percentage share
mt_linear_attribution = (mt_linear_total_credits / len(converting_users)) * 100
mt_linear_attribution = mt_linear_attribution.reset_index()
mt_linear_attribution.columns = ['Channel', 'Linear_MT_%']

print("--- Linear Multi-Touch Attribution (% of Converters) ---")
print(mt_linear_attribution)
print("\n")

# --- 7b. U-Shaped Model (40% First, 40% Last, 20% Middle) ---
def apply_u_shaped(group):
    """Applies U-shaped attribution (40% first, 40% last, 20% middle)."""
    n = len(group)
    if n == 0:
        return pd.Series(dtype=float)

    # Get the list of channels in chronological order for the user
    channels = group['channel'].tolist()
    # Initialize a Series to store credits for each unique channel in this journey
    unique_channels_in_journey = pd.unique(channels)
    credits = pd.Series(0.0, index=unique_channels_in_journey)

    if n == 1:
        # If only one touch, it gets 100% credit
        credits[channels[0]] = 1.0
    elif n == 2:
        # If two touches, split 50/50
        credits[channels[0]] += 0.5 # Use += in case the same channel is first and last
        credits[channels[1]] += 0.5
    else:
        # More than two touches: 40% first, 40% last, 20% middle
        # First touch credit
        credits[channels[0]] += 0.4
        # Last touch credit
        credits[channels[-1]] += 0.4
        # Middle touches credit
        middle_channels = channels[1:-1]
        if middle_channels: # Check if there are actually middle channels (n > 2)
             middle_credit_split = 0.2 / len(middle_channels)
             for channel in middle_channels:
                 credits[channel] += middle_credit_split
            # If n=3, middle_channels is empty, no middle credit needed

    # Optional: Normalize per user to ensure sum is exactly 1, handles potential float issues
    # if credits.sum() > 0:
    #    return credits / credits.sum()
    return credits


# Apply the U-shaped function
u_shaped_credits_per_user = journeys_converters.groupby('user', group_keys=True).apply(apply_u_shaped)

# Sum credits across all converting users for each channel
if isinstance(u_shaped_credits_per_user.index, pd.MultiIndex):
     mt_u_shaped_total_credits = u_shaped_credits_per_user.groupby(level='channel').sum()
else:
    mt_u_shaped_total_credits = u_shaped_credits_per_user.groupby(u_shaped_credits_per_user.index).sum()


# Normalize by the number of converters
mt_u_shaped_attribution = (mt_u_shaped_total_credits / len(converting_users)) * 100
mt_u_shaped_attribution = mt_u_shaped_attribution.reset_index()
mt_u_shaped_attribution.columns = ['Channel', 'U_Shaped_MT_%']

print("--- U-Shaped Multi-Touch Attribution (% of Converters) ---")
print(mt_u_shaped_attribution)
print("\n")


# --- 8. Compare Distributions and Analyze Shifts ---
# Merge the attribution results into a single DataFrame
# Start with LT attribution
comparison_df = lt_attribution.copy()
# Merge Linear MT results
comparison_df = pd.merge(comparison_df, mt_linear_attribution, on='Channel', how='outer')
# Merge U-Shaped MT results
comparison_df = pd.merge(comparison_df, mt_u_shaped_attribution, on='Channel', how='outer')

# Fill NaN values with 0 (for channels present in one model but not another after merge)
comparison_df = comparison_df.fillna(0)

# Calculate shifts: Multi-Touch % - Last_Touch %
comparison_df['Shift (Linear - LT)'] = comparison_df['Linear_MT_%'] - comparison_df['Last_Touch_%']
comparison_df['Shift (U-Shaped - LT)'] = comparison_df['U_Shaped_MT_%'] - comparison_df['Last_Touch_%']

# Select and order columns for the final report
report_columns = ['Channel', 'Last_Touch_%', 'Linear_MT_%', 'Shift (Linear - LT)', 'U_Shaped_MT_%', 'Shift (U-Shaped - LT)']
comparison_df = comparison_df[report_columns]

# Format for readability (optional)
comparison_df = comparison_df.round(2)

print("--- Attribution Model Comparison (% Credit Share & Shifts) ---")
print(comparison_df)
print("\n")

print("Interpretation Guide:")
print("- Positive Shift (MT - LT): Indicates the channel plays a larger role earlier or mid-journey than last-touch suggests (Introducer/Influencer).")
print("- Negative Shift (MT - LT): Indicates the channel is more dominant as a final touchpoint (Closer) and potentially overvalued by Last-Touch alone relative to its full journey contribution.")
print("- Results depend heavily on the random simulation of converters and the chosen CONVERSION_RATE.")
print("- This analysis assumes conversion happens exactly at the last touch for the simulated converters.")

