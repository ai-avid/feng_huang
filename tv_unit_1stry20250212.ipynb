{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_length\n",
      "15    0.411765\n",
      "30    0.600000\n",
      "Name: convert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Sean/Desktop/UoPX/tv_unit.csv\")\n",
    "\n",
    "# Assume you've already read your CSV into a DataFrame `df`\n",
    "# e.g., df = pd.read_csv(\"path/to/your_data.csv\")\n",
    "\n",
    "# Group by `ad_length` and calculate the mean of `convert`\n",
    "conversion_by_length = df.groupby('ad_length')['convert'].mean()\n",
    "\n",
    "print(conversion_by_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Conversion rate for 15-second ads:', 0.41176470588235292)\n",
      "('Conversion rate for 30-second ads:', 0.59999999999999998)\n"
     ]
    }
   ],
   "source": [
    "conversion_rate_15 = df[df['ad_length'] == 15]['convert'].mean()\n",
    "conversion_rate_30 = df[df['ad_length'] == 30]['convert'].mean()\n",
    "\n",
    "print(\"Conversion rate for 15-second ads:\", conversion_rate_15)\n",
    "print(\"Conversion rate for 30-second ads:\", conversion_rate_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ip_address    ad_date ad_name  ad_length  convert convert_date  ad_signal\n",
      "0         ip1   1/1/2023     ad1         15        0          NaN        1.0\n",
      "1         ip1   2/6/2023     ad2         15        0          NaN        1.0\n",
      "2         ip1   3/9/2023     ad3         15        0          NaN        1.0\n",
      "3         ip1   7/6/2023     ad1         30        0          NaN        2.0\n",
      "4         ip1   8/4/2023     ad4         15        0          NaN        1.0\n",
      "5         ip2   1/1/2023     ad1         15        1   10/10/2023        1.0\n",
      "6         ip2   3/6/2023     ad2         15        1   10/10/2023        1.0\n",
      "7         ip2   3/9/2023     ad3         15        1   10/10/2023        1.0\n",
      "8         ip2   7/6/2023     ad1         30        1   10/10/2023        2.0\n",
      "9         ip2   8/4/2023     ad4         15        1   10/10/2023        1.0\n",
      "10        ip2   8/7/2023     ad2         15        1   10/10/2023        1.0\n",
      "11        ip2   9/1/2023     ad3         30        1   10/10/2023        2.0\n",
      "12        ip2   9/3/2023     ad4         15        1   10/10/2023        1.0\n",
      "13        ip2  9/10/2023     ad2         30        1   10/10/2023        2.0\n",
      "14        ip2  9/13/2023     ad3         15        1   10/10/2023        1.0\n",
      "15        ip3   3/6/2023     ad4         15        0          NaN        1.0\n",
      "16        ip3   3/9/2023     ad2         15        0          NaN        1.0\n",
      "17        ip3   7/6/2023     ad3         30        0          NaN        2.0\n",
      "18        ip3   8/4/2023     ad4         15        0          NaN        1.0\n",
      "19        ip3   8/7/2023     ad2         15        0          NaN        1.0\n",
      "20        ip3   9/1/2023     ad1         15        0          NaN        1.0\n",
      "21        ip3   9/9/2023     ad3         15        0          NaN        1.0\n"
     ]
    }
   ],
   "source": [
    "conditions = [\n",
    "    df['ad_length'] == 15,\n",
    "    df['ad_length'] == 30\n",
    "]\n",
    "choices = [1, 2]\n",
    "\n",
    "# Use np.select to create the ad_signal column. \n",
    "# For ad_length values that don't match, it returns np.nan (you can change this default if desired).\n",
    "df['ad_signal'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chi-square:', 0.053921568627450893)\n",
      "('p-value:', 0.81637476978602408)\n",
      "('Degrees of freedom:', 1L)\n",
      "('Expected frequencies:\\n', array([[ 9.27272727,  7.72727273],\n",
      "       [ 2.72727273,  2.27272727]]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Build a contingency table for convert (0 or 1) vs. ad_length=30 or not\n",
    "df['is_30sec'] = (df['ad_length'] == 30).astype(int)\n",
    "\n",
    "contingency_table = pd.crosstab(df['is_30sec'], df['convert'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-square:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ip_address    ad_date ad_name  ad_length  convert convert_date  ad_signal  \\\n",
      "0         ip1 2023-01-01     ad1         15        0          NaN        1.0   \n",
      "1         ip1 2023-02-06     ad2         15        0          NaN        1.0   \n",
      "2         ip1 2023-03-09     ad3         15        0          NaN        1.0   \n",
      "3         ip1 2023-07-06     ad1         30        0          NaN        2.0   \n",
      "4         ip1 2023-08-04     ad4         15        0          NaN        1.0   \n",
      "5         ip2 2023-01-01     ad1         15        1   10/10/2023        1.0   \n",
      "6         ip2 2023-03-06     ad2         15        1   10/10/2023        1.0   \n",
      "7         ip2 2023-03-09     ad3         15        1   10/10/2023        1.0   \n",
      "8         ip2 2023-07-06     ad1         30        1   10/10/2023        2.0   \n",
      "9         ip2 2023-08-04     ad4         15        1   10/10/2023        1.0   \n",
      "10        ip2 2023-08-07     ad2         15        1   10/10/2023        1.0   \n",
      "11        ip2 2023-09-01     ad3         30        1   10/10/2023        2.0   \n",
      "12        ip2 2023-09-03     ad4         15        1   10/10/2023        1.0   \n",
      "13        ip2 2023-09-10     ad2         30        1   10/10/2023        2.0   \n",
      "14        ip2 2023-09-13     ad3         15        1   10/10/2023        1.0   \n",
      "15        ip3 2023-03-06     ad4         15        0          NaN        1.0   \n",
      "16        ip3 2023-03-09     ad2         15        0          NaN        1.0   \n",
      "17        ip3 2023-07-06     ad3         30        0          NaN        2.0   \n",
      "18        ip3 2023-08-04     ad4         15        0          NaN        1.0   \n",
      "19        ip3 2023-08-07     ad2         15        0          NaN        1.0   \n",
      "20        ip3 2023-09-01     ad1         15        0          NaN        1.0   \n",
      "21        ip3 2023-09-09     ad3         15        0          NaN        1.0   \n",
      "\n",
      "     adstock  \n",
      "0   1.000000  \n",
      "1   1.027324  \n",
      "2   1.046280  \n",
      "3   2.000007  \n",
      "4   1.110047  \n",
      "5   1.000000  \n",
      "6   1.001662  \n",
      "7   1.742049  \n",
      "8   2.000012  \n",
      "9   1.110047  \n",
      "10  1.822343  \n",
      "11  2.149587  \n",
      "12  2.759933  \n",
      "13  3.370542  \n",
      "14  3.496959  \n",
      "15  1.000000  \n",
      "16  1.740818  \n",
      "17  2.000012  \n",
      "18  1.110047  \n",
      "19  1.822343  \n",
      "20  1.149587  \n",
      "21  1.516543  \n"
     ]
    }
   ],
   "source": [
    "# adstocking of column ad_length\n",
    "\n",
    "\n",
    "# Convert the ad_date column to datetime.\n",
    "df['ad_date'] = pd.to_datetime(df['ad_date'], format='%m/%d/%Y')\n",
    "\n",
    "# Define the decay rate (lambda) per day.\n",
    "decay_rate = 0.1\n",
    "\n",
    "def compute_adstock(group, decay_rate=decay_rate):\n",
    "    # Sort the group by ad_date.\n",
    "    group = group.sort_values('ad_date').copy()\n",
    "    \n",
    "    adstock_values = []\n",
    "    previous_adstock = 0\n",
    "    previous_date = None\n",
    "    \n",
    "    # Iterate through the rows in the sorted group.\n",
    "    for _, row in group.iterrows():\n",
    "        # For the first row, no prior ad exists.\n",
    "        if previous_date is None:\n",
    "            effective_decay = 1  # No decay applied.\n",
    "        else:\n",
    "            # Calculate the time difference in days.\n",
    "            delta_days = (row['ad_date'] - previous_date).days\n",
    "            # Calculate effective decay factor based on the time difference.\n",
    "            effective_decay = np.exp(-decay_rate * delta_days)\n",
    "        \n",
    "        # Compute current adstock.\n",
    "        current_adstock = row['ad_signal'] + effective_decay * previous_adstock\n",
    "        \n",
    "        # Append the computed adstock.\n",
    "        adstock_values.append(current_adstock)\n",
    "        \n",
    "        # Update previous values.\n",
    "        previous_adstock = current_adstock\n",
    "        previous_date = row['ad_date']\n",
    "    \n",
    "    # Add the computed adstock values as a new column.\n",
    "    group['adstock'] = adstock_values\n",
    "    return group\n",
    "\n",
    "# Apply the adstock calculation for each ip_address group.\n",
    "df = df.groupby('ip_address', group_keys=False).apply(compute_adstock)\n",
    "\n",
    "# Display the DataFrame with the new 'adstock' column.\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
